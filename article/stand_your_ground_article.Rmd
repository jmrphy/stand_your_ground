---
title: "Racial Bias in \"Stand Your Ground\" Cases in Florida, 2006-2013"
date: "`r format(Sys.time(), '%d %B %Y')`"
author: Justin Murphy  \\ University of Southampton
output:
  pdf_document:
    fig_caption: yes
    includes:
      in_header: mystyles.sty
      before_body: prefix.tex
    keep_tex: yes
    latex_engine: xelatex
    toc: no
citecolor: MidnightBlue
fontsize: 12pt
geometry: margin=1.25in
linkcolor: MidnightBlue
classoption: article
urlcolor: RoyalBlue
bibliography: mybib.bib
---

"Stand your ground" (SYG) laws have become one of the most polarizing legal institutions in the United States, most notably after George Zimmerman claimed an SYG defense in his 2012 trial for the murder of Trayvon Martin. "Stand your ground" laws, now in effect in most US states, are laws which empower individuals to use any force necessary to defend themselves against anyone they believe to be an imminent threat of bodily harm, and do not require them to retreat even when possible.

**This article presents one of the first statistical analyses of racial bias in the outcome of SYG cases which is able to control for a wide variety of contextual factors**. It is also the first investigation with completely reproducible code (publicly available here) and data (publicly available here). I gather data on first made available by the Tampa Bay Times

Two findings are notable. First, there is surprisingly little evidence that the outcomes of SYG cases are shaped by objective factors related to the necessity of self-defense. 

#### 2. The "stand your ground" defense has *nearly zero* probability of succeeding when the victim is white and the defendant is a person of color.

Remember that this is true after accounting for more than ten objective factors related to the crime. The Tampa Bay Times made a similar finding but since they did not use a statistical model they could not infer racial bias. As they admit, "The Times analysis does not prove that race caused the disparity between cases with black and white victims. Other factors may be at play.' While no honest statistician ever uses the word "prove," the findings presented here do allow us to infer that people of color who claim "stand your ground" against white people have, on average, nearly zero chance of winning. Although there is uncertainty around that estimate, the model shows that we can be statistically confident (at a 95% confidence level) that "stand your ground" defenses against white victims are more likely to fail than against non-white victims in otherwise equivalent cases. We can also be statistically confident (a 94% confidence level) that a white defendant is less likely to be convicted against a white victim than a non-white defendant is against a white victim.


## Background and Literature Review

"Stand your ground" laws, adopted by most US states, are laws which suggest that "an individual has no duty to retreat from any place they have lawful right to be and [may use any level of force, including lethal](http://en.wikipedia.org/wiki/Stand-your-ground_law), if they reasonably believe they face an imminent and immediate threat of serious bodily harm or death."

"Stand your ground" laws are supposed to be about empowering people to defend themselves against aggressors, but many argue that they serve to protect a racial order of white supremacy.

Most famously, George Zimmerman claimed a "stand your ground" defense for the killing of Trayvon Martin.

The [Tampa Bay Times](http://www.tampabay.com/stand-your-ground-law) has organized a wealth of information regarding every case in which someone from the state of Florida has claimed a "stand your ground" defense since 2006.
The Tampa Bay Times wrote up several excellent analyses of their data, however, their analyses only look at descriptive cross-sections of the data. They explore the data interestingly and revealing, but simply describing how the data breaks down into different groups always leaves the analyst vulnerable to counter-explanations (for instance, the what if black people are just more violent?" retort). As the [Tampa Bay Times concedes](http://www.tampabay.com/news/courts/criminal/race-plays-complex-role-in-floridas-stand-your-ground-law/1233152):

As far as I know, the only other direct statistical test of racism in the enforcement of "stand your ground" laws is one statistical analysis by gun advocate John Lott submitted in testimony to the US Senate Judiciary Committee [@JohnRLott:2013wd]. Using data collected by the Tampa Bay Times, Lott conducts two logistic regression analyses on the probability a defendant will be convicted when SYG is argued. On the basis of these two regression analysis, Lott submits that there is no evidence of racial bias in SYG cases. However, Lott's statistical analysis is problematic in several important ways. The first problem is that the analysis does not provide any discussion of how the Tampa Bay Times data were pre-processed for analysis. As will become clear in the section below on Data and Method, organizing the Tampa Bay Times data for statistical analysis requires the analyst to make several non-trivial and non-obvious decisions. However, the analysis submitted in the US Senate testimony provides no such discussion. As only one example, the Tampa Bay Times provides several categories for the legal outcome of cases, including "conviction" but also "plea", "acquittal", "immunity", etc. The distinction between what should be counted as "conviction" and "not conviction" is far from obvious and, as with all statistical analysis, requires reasoned argument and transparency from the analyst. Yet, Lott provides no discussion. Second, his models only include as many as 78 of the total 237 cases. Because there is no discussion of the data cleaing process, it is unclear why the analysis is conducted on less than one third of the total cases, but it leaves open the significant question of whether one might find different results if more cases were to be included.  Third, both of his two regression models are overfit, with each one having at least one case completley determined by the predictors. Regression analysis assumes that the dependent variable is a function of several predictors and some error term or, in other words, it assumes a systematic and stochastic component in the process that generated the dependent variable. Overfitting means that for some cases there is no error or stochastic component; it is a problem because it effectively means that some of the predictors in the model are interpreting error (noise) as a systematic association with predictors (signal). For this reason, overfit models are known to have poor predictive performance. Fourth, he does not include several variables recorded by the Tampa Bay Times which are plausible predictors of outcomes, such as gender and age of victims and defendants, the county in which the incident occurred, weapon used by defendant, or whether the victim died.

Most published academic studies of SYG laws have focused on the effect of SYG laws on homicide rates rather than possible racism in enforcement. For instance, Cheng and Hoekstra [-@Cheng:2013wb] find that SYG laws fail to deter burglary, robbery, or assault but increase murder rates by about 8 percent on net. McClellan and Tekin [@McCellan:2012vr] also find that SYG laws lead to an increase of homicides but that the victims are disproprtionately white males.

The only previous study which focuses on the effect of SYG laws on racial disparities in legal outcomes is one by Roman [-@Roman:2013tq], which uses data from the Federal Bureau of Investigations Supplementary Homicide Report to model the ruling of justified homicides. Roman reports robust evidence of racial bias, finding that, compared to white-on-white homicides, black-on-white homicides have about half the odds of being ruled justified and that this disparity is worse in states with SYG laws.[@Roman:2013tq, 9] While Roman's findings appear robust, that study has two key limitations. The first is that the effect of SYG laws is only considered at the state level as a factor which shapes individual rulings of justifiable homicide. For this reason the analysis does not give us direct insight into the subset of cases which specifically involve SYG claims. The second shortcoming is that Roman is unable to control for important facts related to the specific cases. This is crucial because--as many conservative pundits argue and Roman rightly acknowledges--*if* white-on-black homicides are more likely to be legitimate cases of self-defense than black-on-white homicides, then racial disparity in rulings of justifiable homicide may not reflect racism but rather objective differences in crime rates across racial groups. Because the Tampa Bay Times data contains information on precisely such contextual factors, the present study allows us to account for the claim that people of color are more likely to engage in violent crime.


## Data and Methodoloy

To test for the possibility of racial bias in SYG cases, I gathered all the available data made available on the Tampa Bay Times website.^[I began by downloading a spreadsheet made available by the Tampa Bay Times, which included only a small subset of the relevant variables included elsewhere on their website. To supplement this spreadsheet with the other factors available only through the separate webpages for each individual case, I used Import.IO to crawl and scrape the webpage of each case automatically. I then merged, cleaned, and pre-processed the spreadsheet made available by the Times and the spreasheet of scraped information.] The final result was a data matrix of Z cases and Y variables. The data matrix contains indicators for all the following factors related to each case, with the names I assigned each variable in parentheses.

- Did the victim initiate the incident?
- Could the defendant retreat?
- Did the defendant pursue the victim?
- Did the incident take place on the defendant's property?
- Was the victim killed?
- How old was the victim and defendant?
- Was there physical evidence?
- Was there at least one witness?
- Was the victim committing a crime?
- Were the victim and defendant white or non-white (Black, Hispanic, or "other")?
- Were the victim and defendant female or male? (Transgender identities were not gauged)
- Which county did the incident occur in?
- Is there a time trend?

For the present analysis, conviction refers to any case in which the defendant received a guilty verdict or took a plea deal; non-convictions refer to any case in which the defendant was acquitted, dismissed, granted immunity, or not charged.^[The inclusion of plea deals with guilty verdicts is not ideal because those who take pleas are not necessarily guilty. I considered removing plea deals row-wise but, given that they are almost as frequent as guilty verdicts (33, and 40, respectively), it does not seem that the improvement of the measure would be so great as to outweigh the loss of information from row-wise deletion. Furthermore, including plea deals with guilty verdicts is theoretically sensible because pleas are likely driven by the expectation that the defendant would be found guilty if tried. Of course, racial identity might shape whether a defendant fears they will be found guilty (innocent or not), but if that is the case then that is precisely why it is best to keep that information in the category of conviction.]

After scraping, cleaning, and merging the data from the Tampa Bay Times website, I conducted a series of logistic regression analyses modeling the odds of conviction as a function of the independent variables listed above. Logistic regression analysis allows one to estimate the relationship between multiple independent variables on some dichotomous outcome. The analysis uses Huber-White standard errors given the possibility of spatial and temporal dependence. 


If previously observed racial bias is simply due to the fact one racial group commits more or worse crimes, or because one racial group more often has to defend itself from  then the coefficients for race should
In other words, if anyone says that my estimated effects aren't real and that it's only because some group is more likely to do/be more violent, more likely to be the attacker, or more likely to live in a poor county where crime in general is worse, you can say "No, these are the effects *after* subtracting whatever effect that correlation might have."

## Analysis

```{r, echo=FALSE, results='hide', message=FALSE, error=FALSE}
setwd("~/Dropbox/gh_projects/florida_syg")
df<-read.csv("cleaned_data/convict_model_data.csv", stringsAsFactors=TRUE)

df$conviction<-factor(df$conviction, levels=c("No Conviction", "Conviction"))
df$victim_unarmed<-factor(df$victim_unarmed, levels=c("Victim not clearly unarmed", "Victim clearly unarmed"))
df$victim_crime<-factor(df$victim_crime, levels=c("Victim was not clearly committing a crime", "Victim was committing a crime"))
df$could_retreat<-factor(df$could_retreat, levels=c("Defendant could not clearly have retreated", "Defendant could have retreated"))
df$accused_weapon<-factor(df$accused_weapon, levels=c("Defendant did not clearly have a gun", "Defendant clearly had a gun"))
df$witness<-factor(df$witness, levels=c("No clear witness(es)", "Clear witness(es)"))


```

\singlespacing
```{r, echo=FALSE, results='asis', cache=FALSE, message=FALSE, error=FALSE}
require(Zelig)
require(stargazer)

# Killing white people is more likely to lead to conviction
model1<-zelig(conviction ~ victim_initiated + victim_crime + victim_unarmed + defendant_pursued +
                            could_retreat + accused_weapon + deaths + witness +
                            physical_evidence + defendant_property +  victim_race +
                            victim_gender + victim_age + accused_race + accused_gender +
                            accused_age + county + year,
      data=df,
      model="logit",
      cite=FALSE,
      robust=TRUE)
model1classif<-table(model1$result$fitted.values>.5, model1$result$y)
model1correct<-(model1classif[1,1] + model1classif[2,2])
# (model1correct/nrow(df))*100
# summary(model1)

model2<-zelig(conviction ~ victim_initiated + victim_crime + victim_unarmed + defendant_pursued +
                            could_retreat + accused_weapon + deaths + witness +
                            physical_evidence + defendant_property +  victim_race +
                            victim_gender + victim_age + accused_race + accused_gender +
                            accused_age + victim_race:accused_race +
                            victim_gender:accused_gender + victim_race:victim_gender +
                            accused_race:accused_gender + county + year,
      data=df,
      model="logit",
      cite=FALSE,
      robust=TRUE)

model2classif<-table(model2$result$fitted.values>.5, model2$result$y)
model2correct<-(model2classif[1,1] + model2classif[2,2])
# (model2correct/nrow(df))*100
# summary(model2)

model2<-zelig(conviction ~ victim_initiated + victim_crime + victim_unarmed + defendant_pursued +
                            could_retreat + accused_weapon + deaths + witness +
                            physical_evidence + defendant_property +  victim_race +
                            victim_gender + victim_age + accused_race + accused_gender +
                            accused_age + victim_race:accused_race +
                            victim_gender:accused_gender + victim_race:victim_gender +
                            accused_race:accused_gender,
      data=df,
      model="logit",
      cite=FALSE,
      robust=TRUE)


stargazer(model1, model2, header=FALSE, font.size="footnotesize",
          keep=c("victim_initiated", "victim_crime", "victim_unarmed", "defendant_pursued", "could_retreat",
                        "accused_weapon", "deaths", "witness",
                        "physical_evidence", "defendant_property","victim_race", "victim_gender",
                        "victim_age", "accused_race", "accused_gender", "accused_age",
                        "victim_race:accused_race", "victim_gender:accused_gender",
                        "victim_race:victim_gender", "accused_race:accused_gender")
          )
```


```{r, echo=FALSE, fig.height=5, fig.width=7, cache=TRUE, message=FALSE, fig.cap="Effect of Victim's Race on Probability of Conviction for White and Non-White Defendants"}
mainmodel<-glm(conviction ~ victim_initiated + victim_crime + victim_unarmed + defendant_pursued +
                            could_retreat + accused_weapon + deaths + witness +
                            physical_evidence + defendant_property +  victim_race +
                            victim_gender + victim_age + accused_race + accused_gender +
                            accused_age + victim_race:accused_race +
                            victim_gender:accused_gender + victim_race:victim_gender +
                            accused_race:accused_gender + county + year,
                            data=df,
                            family=binomial())  
require(visreg)

visreg(mainmodel, "victim_race", by="accused_race", scale="response", xlab="", ylab="Probability of Conviction", rug=3, alpha=.05, cond=list())
```

```{r, echo=FALSE, fig.height=4, fig.width=5, cache=TRUE, message=FALSE, fig.cap="lskjdflkj"}
require(visreg)

# Gender effects for white defendants against poc victims
visreg(mainmodel, "victim_gender", by="accused_gender", scale="response", xlab="", ylab="Probability of Conviction", rug=3, alpha=.05, cond=list(accused_race="White defendant"), main="White Defendants")
```

```{r, echo=FALSE, fig.height=4, fig.width=5, cache=TRUE, message=FALSE, fig.cap="lskjsdfsdfflkj"}
require(visreg)
# Gender effects for poc defendents against white victims
visreg(mainmodel, "victim_gender", by="accused_gender", scale="response", xlab="", ylab="Probability of Conviction", rug=3, alpha=.05, cond=list(accused_race="Non-white defendant"), main="PoC Defendants")
```

## Conclusion



